{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d353d4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report,f1_score\n",
    "from sklearn.model_selection import RepeatedKFold, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef1cd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shree\\AppData\\Local\\Temp\\ipykernel_9980\\1944357366.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category  Size_in_Mb  Content_Rating  Ad_Supported  In_App_Purchases  \\\n",
      "0         0        10.0               0             0                 0   \n",
      "1         1         2.9               0             1                 0   \n",
      "2         2         3.7               0             0                 0   \n",
      "3         3         1.8               0             1                 0   \n",
      "4         1         6.2               0             0                 0   \n",
      "\n",
      "   Transformed_Rating  Installs  Free  Rating_Count  Editors_Choice  \n",
      "0                   0        10     1             0               0  \n",
      "1                   4      5000     1            64               0  \n",
      "2                   0        50     1             0               0  \n",
      "3                   5        10     1             5               0  \n",
      "4                   0       100     1             0               0  \n"
     ]
    }
   ],
   "source": [
    "# Connect to SQL Server\n",
    "conn = mysql.connector.connect(host=\"localhost\", user=\"root\", password=\"root\", database=\"GooglePlayStore\")\n",
    "# Fetch Data\n",
    "query = \"SELECT * FROM rating_pred\"\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "df = df.drop('id', axis=1)\n",
    "# Show first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65c4986e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2237013, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52668d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformed_Rating\n",
       "0    1046271\n",
       "4     561859\n",
       "5     412277\n",
       "3     173693\n",
       "2      38770\n",
       "1       4143\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Transformed_Rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac86d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New DataFrame Shape: (1537013, 10)\n"
     ]
    }
   ],
   "source": [
    "zero_rating_rows = df[df[\"Transformed_Rating\"] == 0]\n",
    "rows_to_drop = zero_rating_rows.sample(n=700000, random_state=42)\n",
    "# Drop these rows from the original DataFrame\n",
    "df = df.drop(rows_to_drop.index).reset_index(drop=True)\n",
    "print(\"New DataFrame Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0685ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformed_Rating\n",
       "4    561859\n",
       "5    412277\n",
       "0    346271\n",
       "3    173693\n",
       "2     38770\n",
       "1      4143\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Transformed_Rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5d2eae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Original Class Distribution: Counter({4: 561859, 5: 412277, 0: 346271, 3: 173693, 2: 38770, 1: 4143})\n",
      "New DataFrame Shape: (1537013, 10)\n",
      "ðŸ”¹ After SMOTETomek: Counter({0: 393291, 1: 388089, 2: 376311, 3: 364145, 5: 353763, 4: 343229})\n",
      "X shape: (2218828, 9), Y shape: (2218828,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Load dataset\n",
    "X = df.drop(\"Transformed_Rating\", axis=1)  # Features\n",
    "Y = df[\"Transformed_Rating\"]  # Target variable\n",
    "\n",
    "print(\"ðŸ”¹ Original Class Distribution:\", Counter(Y))\n",
    "print(\"New DataFrame Shape:\", df.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=0.3, random_state=7,stratify=Y)\n",
    "smote_tomek = SMOTETomek(random_state=7)\n",
    "X_train_resampled, Y_train_resampled = smote_tomek.fit_resample(X_train, Y_train)\n",
    "print(\"ðŸ”¹ After SMOTETomek:\", Counter(Y_train_resampled))\n",
    " \n",
    "print(f\"X shape: {X_train_resampled.shape}, Y shape: {Y_train_resampled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2676efdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1537013, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ddc00fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoosting Classifier Accuracy: 0.5701165030014921\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    103881\n",
      "           1       0.01      0.34      0.02      1243\n",
      "           2       0.08      0.32      0.12     11631\n",
      "           3       0.25      0.17      0.20     52108\n",
      "           4       0.61      0.49      0.54    168558\n",
      "           5       0.65      0.52      0.57    123683\n",
      "\n",
      "    accuracy                           0.57    461104\n",
      "   macro avg       0.43      0.47      0.41    461104\n",
      "weighted avg       0.65      0.57      0.60    461104\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[103881      0      0      0      0      0]\n",
      " [     0    419    326    120    186    192]\n",
      " [     0   2287   3683   1802   2773   1086]\n",
      " [     0   7074  11551   8976  19447   5060]\n",
      " [     0  16437  22249  19285  82090  28497]\n",
      " [     0  14511  10115   5844  29379  63834]]\n",
      "\n",
      "Log Loss: 0.9883634253012161\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, log_loss, roc_auc_score\n",
    "\n",
    "# Initialize and train the model\n",
    "hgbc = HistGradientBoostingClassifier(max_iter=100, learning_rate=0.1, random_state=7)\n",
    "hgbc.fit(X_train_resampled, Y_train_resampled)\n",
    "\n",
    "# Predictions and probabilities\n",
    "y_pred = hgbc.predict(X_test)\n",
    "y_prob = hgbc.predict_proba(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "hgbc_ac = accuracy_score(Y_test, y_pred)\n",
    "print(\"HistGradientBoosting Classifier Accuracy:\", hgbc_ac)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, y_pred))\n",
    "\n",
    "# Log Loss\n",
    "hgbc_log_loss = log_loss(Y_test, y_prob)\n",
    "print(\"\\nLog Loss:\", hgbc_log_loss)\n",
    "\n",
    "# ROC-AUC Score (only if the problem is binary classification)\n",
    "if len(np.unique(Y_test)) == 2:\n",
    "    hgbc_roc_auc = roc_auc_score(Y_test, y_prob[:, 1])\n",
    "    print(\"\\nROC-AUC Score:\", hgbc_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a3ff2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Accuracy: 0.4201503348485374\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\shree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\shree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.34      0.50    103881\n",
      "           1       0.00      0.00      0.00      1243\n",
      "           2       0.00      0.00      0.00     11631\n",
      "           3       0.07      0.17      0.10     52108\n",
      "           4       0.50      0.85      0.63    168558\n",
      "           5       0.60      0.04      0.08    123683\n",
      "\n",
      "    accuracy                           0.42    461104\n",
      "   macro avg       0.35      0.23      0.22    461104\n",
      "weighted avg       0.56      0.42      0.37    461104\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 35689      0      0  68192      0      0]\n",
      " [     3      0      0    335    888     17]\n",
      " [     6      0      0   2165   9377     83]\n",
      " [    35      0      0   8684  43022    367]\n",
      " [   316      0      0  21176 144079   2987]\n",
      " [  2734      0      0  22697  92971   5281]]\n",
      "\n",
      "Log Loss: 1.7221447002161394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train Logistic Regression\n",
    "logreg_c = LogisticRegression(max_iter=500, random_state=7, class_weight='balanced')\n",
    "logreg_c.fit(X_train_resampled, Y_train_resampled)\n",
    "\n",
    "# Predictions and probabilities for Logistic Regression\n",
    "logreg_pred = logreg_c.predict(X_test)\n",
    "logreg_prob = logreg_c.predict_proba(X_test)\n",
    "\n",
    "logreg_ac = accuracy_score(Y_test, logreg_pred)\n",
    "print(\"\\nLogistic Regression Accuracy:\", logreg_ac)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, logreg_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, logreg_pred))\n",
    "\n",
    "logreg_log_loss = log_loss(Y_test, logreg_prob)\n",
    "print(\"\\nLog Loss:\", logreg_log_loss)\n",
    "\n",
    "if len(np.unique(Y_test)) == 2:\n",
    "    logreg_roc_auc = roc_auc_score(Y_test, logreg_prob[:, 1])\n",
    "    print(\"\\nROC-AUC Score:\", logreg_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c375a775",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous-multioutput. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize and train RandomForestClassifier\u001b[39;00m\n\u001b[0;32m      2\u001b[0m rdf_c \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mrdf_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m rdf_pred \u001b[38;5;241m=\u001b[39m rdf_c\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      6\u001b[0m rdf_prob \u001b[38;5;241m=\u001b[39m rdf_c\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n",
      "File \u001b[1;32mc:\\Users\\shree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:419\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    413\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSum of y is not strictly positive which \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    414\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis necessary for Poisson regression.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    415\u001b[0m         )\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m--> 419\u001b[0m y, expanded_class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_y_class_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m!=\u001b[39m DOUBLE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mcontiguous:\n\u001b[0;32m    422\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(y, dtype\u001b[38;5;241m=\u001b[39mDOUBLE)\n",
      "File \u001b[1;32mc:\\Users\\shree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:831\u001b[0m, in \u001b[0;36mForestClassifier._validate_y_class_weight\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_validate_y_class_weight\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[1;32m--> 831\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(y)\n\u001b[0;32m    834\u001b[0m     expanded_class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:222\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    214\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m ]:\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    226\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: continuous-multioutput. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "# Initialize and train RandomForestClassifier\n",
    "rdf_c = RandomForestClassifier(random_state=7)\n",
    "rdf_c.fit(X_train_resampled, Y_train_resampled)\n",
    "\n",
    "rdf_pred = rdf_c.predict(X_test)\n",
    "rdf_prob = rdf_c.predict_proba(X_test)\n",
    "\n",
    "rdf_ac = accuracy_score(Y_test, rdf_pred)\n",
    "print(\"\\nRandomForest Accuracy:\", rdf_ac)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, rdf_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, rdf_pred))\n",
    "\n",
    "rdf_log_loss = log_loss(Y_test, rdf_prob)\n",
    "print(\"\\nLog Loss:\", rdf_log_loss)\n",
    "\n",
    "if len(np.unique(Y_test)) == 2:\n",
    "    rdf_roc_auc = roc_auc_score(Y_test, rdf_prob[:, 1])\n",
    "    print(\"\\nROC-AUC Score:\", rdf_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0e241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train DecisionTreeClassifier\n",
    "dtree_c = DecisionTreeClassifier(random_state=7, criterion='entropy', max_depth=10, min_samples_leaf=2, min_samples_split=5)\n",
    "dtree_c.fit(X_train_resampled, Y_train_resampled)\n",
    "\n",
    "dtree_pred = dtree_c.predict(X_test)\n",
    "dtree_prob = dtree_c.predict_proba(X_test)\n",
    "\n",
    "dtree_ac = accuracy_score(Y_test, dtree_pred)\n",
    "print(\"\\nDecisionTreeClassifier Accuracy:\", dtree_ac)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, dtree_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, dtree_pred))\n",
    "\n",
    "dtree_log_loss = log_loss(Y_test, dtree_prob)\n",
    "print(\"\\nLog Loss:\", dtree_log_loss)\n",
    "\n",
    "if len(np.unique(Y_test)) == 2:\n",
    "    dtree_roc_auc = roc_auc_score(Y_test, dtree_prob[:, 1])\n",
    "    print(\"\\nROC-AUC Score:\", dtree_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b792da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Bernoulli Naive Bayes\n",
    "NB = BernoulliNB(binarize=0.0)\n",
    "NB.fit(X_train_resampled, Y_train_resampled)\n",
    "\n",
    "y_pred = NB.predict(X_test)\n",
    "y_prob = NB.predict_proba(X_test)\n",
    "\n",
    "nb_ac = accuracy_score(Y_test, y_pred)\n",
    "print(\"\\nBernoulli Naive Bayes Accuracy:\", nb_ac)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, y_pred))\n",
    "\n",
    "nb_log_loss = log_loss(Y_test, y_prob)\n",
    "print(\"\\nLog Loss:\", nb_log_loss)\n",
    "\n",
    "if len(np.unique(Y_test)) == 2:\n",
    "    nb_roc_auc = roc_auc_score(Y_test, y_prob[:, 1])\n",
    "    print(\"\\nROC-AUC Score:\", nb_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21175e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train XGBoost Classifier\n",
    "xgb = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=7, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(X_train_resampled, Y_train_resampled)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_prob = xgb.predict_proba(X_test)\n",
    "\n",
    "xgb_ac = accuracy_score(Y_test, y_pred)\n",
    "print(\"\\nXGBoost Classifier Accuracy:\", xgb_ac)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, y_pred))\n",
    "\n",
    "xgb_log_loss = log_loss(Y_test, y_prob)\n",
    "print(\"\\nLog Loss:\", xgb_log_loss)\n",
    "\n",
    "if len(np.unique(Y_test)) == 2:\n",
    "    xgb_roc_auc = roc_auc_score(Y_test, y_prob[:, 1])\n",
    "    print(\"\\nROC-AUC Score:\", xgb_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d283ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train LightGBM Classifier\n",
    "lgb_model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=7)\n",
    "lgb_model.fit(X_train_resampled, Y_train_resampled)\n",
    "\n",
    "y_pred = lgb_model.predict(X_test)\n",
    "y_prob = lgb_model.predict_proba(X_test)\n",
    "\n",
    "lgb_ac = accuracy_score(Y_test, y_pred)\n",
    "print(\"\\nLightGBM Classifier Accuracy:\", lgb_ac)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, y_pred))\n",
    "\n",
    "lgb_log_loss = log_loss(Y_test, y_prob)\n",
    "print(\"\\nLog Loss:\", lgb_log_loss)\n",
    "\n",
    "if len(np.unique(Y_test)) == 2:\n",
    "    lgb_roc_auc = roc_auc_score(Y_test, y_prob[:, 1])\n",
    "    print(\"\\nROC-AUC Score:\", lgb_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36be7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train CatBoost Classifier\n",
    "Cat_Boost = CatBoostClassifier(verbose=300, n_estimators=1000, learning_rate=0.2, depth=10, early_stopping_rounds=300)\n",
    "Cat_Boost.fit(X_train_resampled, Y_train_resampled)\n",
    "\n",
    "cb_ac = Cat_Boost.score(X_train_resampled, Y_train_resampled)\n",
    "print(\"\\nCatBoost Accuracy:\", cb_ac)\n",
    "\n",
    "y_pred = Cat_Boost.predict(X_test)\n",
    "y_prob = Cat_Boost.predict_proba(X_test)\n",
    "\n",
    "f1 = f1_score(Y_test, y_pred, average=\"weighted\")\n",
    "print(\"\\nF1 Score:\", f1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, y_pred)) \n",
    "\n",
    "cb_log_loss = log_loss(Y_test, y_prob)\n",
    "print(\"\\nLog Loss:\", cb_log_loss)\n",
    "\n",
    "if len(np.unique(Y_test)) == 2:\n",
    "    cb_roc_auc = roc_auc_score(Y_test, y_prob[:, 1])\n",
    "    print(\"\\nROC-AUC Score:\", cb_roc_auc)\n",
    "\n",
    "# Save model\n",
    "with open(\"finetuning_three.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Cat_Boost, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
