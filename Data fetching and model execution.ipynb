{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d353d4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, log_loss, roc_auc_score,f1_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RepeatedKFold, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "from imblearn.combine import SMOTETomek\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aef1cd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shree\\AppData\\Local\\Temp\\ipykernel_9980\\3033059093.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category  Size_in_Mb  Content_Rating  Ad_Supported  In_App_Purchases  \\\n",
      "0         0        10.0               0             0                 0   \n",
      "1         1         2.9               0             1                 0   \n",
      "2         2         3.7               0             0                 0   \n",
      "3         3         1.8               0             1                 0   \n",
      "4         1         6.2               0             0                 0   \n",
      "\n",
      "   Transformed_Rating  Installs  Free  Rating_Count  Editors_Choice  \n",
      "0                   0        10     1             0               0  \n",
      "1                   4      5000     1            64               0  \n",
      "2                   0        50     1             0               0  \n",
      "3                   5        10     1             5               0  \n",
      "4                   0       100     1             0               0  \n"
     ]
    }
   ],
   "source": [
    "# Connect to SQL Server\n",
    "conn = mysql.connector.connect(host=\"localhost\", user=\"root\", password=\"root\", database=\"GooglePlayStore\")\n",
    "# Fetch Data\n",
    "query = \"SELECT * FROM rating_pred\"\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "df = df.drop('id', axis=1)\n",
    "# Show first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65c4986e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2312683, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52668d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformed_Rating\n",
       "0    1066841\n",
       "4     588290\n",
       "5     423009\n",
       "3     189288\n",
       "2      41028\n",
       "1       4227\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Transformed_Rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dac86d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New DataFrame Shape: (1612683, 10)\n"
     ]
    }
   ],
   "source": [
    "zero_rating_rows = df[df[\"Transformed_Rating\"] == 0]\n",
    "rows_to_drop = zero_rating_rows.sample(n=700000, random_state=42)\n",
    "# Drop these rows from the original DataFrame\n",
    "df = df.drop(rows_to_drop.index).reset_index(drop=True)\n",
    "print(\"New DataFrame Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0685ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformed_Rating\n",
       "4    588290\n",
       "5    423009\n",
       "0    366841\n",
       "3    189288\n",
       "2     41028\n",
       "1      4227\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Transformed_Rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5d2eae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Original Class Distribution: Counter({4: 588290, 5: 423009, 0: 366841, 3: 189288, 2: 41028, 1: 4227})\n",
      "New DataFrame Shape: (1612683, 10)\n",
      "ðŸ”¹ After SMOTETomek: Counter({0: 411793, 1: 406872, 2: 394347, 3: 382047, 5: 371337, 4: 360302})\n",
      "X shape: (2326698, 9), Y shape: (2326698,)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "X = df.drop(\"Transformed_Rating\", axis=1)  # Features\n",
    "Y = df[\"Transformed_Rating\"]  # Target variable\n",
    "\n",
    "print(\"ðŸ”¹ Original Class Distribution:\", Counter(Y))\n",
    "print(\"New DataFrame Shape:\", df.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=0.3, random_state=7,stratify=Y)\n",
    "smote_tomek = SMOTETomek(random_state=7)\n",
    "X_train_resampled, Y_train_resampled = smote_tomek.fit_resample(X_train, Y_train)\n",
    "print(\"ðŸ”¹ After SMOTETomek:\", Counter(Y_train_resampled))\n",
    " \n",
    "print(f\"X shape: {X_train_resampled.shape}, Y shape: {Y_train_resampled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2676efdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1612683, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64bf454a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bernoulli Naive Bayes Accuracy: 0.47844482797821436\n",
      "\n",
      "F1 Score: 0.44980934487263924\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train Bernoulli Naive Bayes\n",
    "NB = BernoulliNB(binarize=0.0)\n",
    "NB.fit(X_train_resampled, Y_train_resampled)\n",
    "\n",
    "y_pred = NB.predict(X_test)\n",
    "y_prob = NB.predict_proba(X_test)\n",
    "\n",
    "nb_ac = accuracy_score(Y_test, y_pred)\n",
    "print(\"\\nBernoulli Naive Bayes Accuracy:\", nb_ac)\n",
    "\n",
    "f1 = f1_score(Y_test, y_pred, average=\"weighted\")\n",
    "print(\"\\nF1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ddc00fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoosting Classifier Accuracy: 0.5778361116565558\n",
      "\n",
      "F1 Score: 0.6101447496478094\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "hgbc = HistGradientBoostingClassifier(max_iter=100, learning_rate=0.1, random_state=7)\n",
    "hgbc.fit(X_train_resampled, Y_train_resampled)\n",
    "\n",
    "y_pred = hgbc.predict(X_test)\n",
    "y_prob = hgbc.predict_proba(X_test)\n",
    "\n",
    "hgbc_ac = accuracy_score(Y_test, y_pred)\n",
    "print(\"HistGradientBoosting Classifier Accuracy:\", hgbc_ac)\n",
    "\n",
    "f1 = f1_score(Y_test, y_pred, average=\"weighted\")\n",
    "print(\"\\nF1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c375a775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomForest Accuracy: 0.5863147342421017\n",
      "\n",
      "F1 Score: 0.600774744141296\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train RandomForestClassifier\n",
    "rdf_c = RandomForestClassifier(random_state=7)\n",
    "rdf_c.fit(X_train_resampled, Y_train_resampled)\n",
    "\n",
    "rdf_pred = rdf_c.predict(X_test)\n",
    "rdf_prob = rdf_c.predict_proba(X_test)\n",
    "\n",
    "rdf_ac = accuracy_score(Y_test, rdf_pred)\n",
    "print(\"\\nRandomForest Accuracy:\", rdf_ac)\n",
    "\n",
    "f1 = f1_score(Y_test, rdf_pred, average=\"weighted\")\n",
    "print(\"\\nF1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0e241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train DecisionTreeClassifier\n",
    "dtree_c = DecisionTreeClassifier(random_state=7, criterion='entropy', max_depth=10, min_samples_leaf=2, min_samples_split=5)\n",
    "dtree_c.fit(X_train_resampled, Y_train_resampled)\n",
    "\n",
    "dtree_pred = dtree_c.predict(X_test)\n",
    "dtree_prob = dtree_c.predict_proba(X_test)\n",
    "\n",
    "dtree_ac = accuracy_score(Y_test, dtree_pred)\n",
    "print(\"\\nDecisionTreeClassifier Accuracy:\", dtree_ac)\n",
    "\n",
    "f1 = f1_score(Y_test, dtree_pred, average=\"weighted\")\n",
    "print(\"\\nF1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21175e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train XGBoost Classifier\n",
    "xgb = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=7, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(X_train_resampled, Y_train_resampled)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_prob = xgb.predict_proba(X_test)\n",
    "\n",
    "xgb_ac = accuracy_score(Y_test, y_pred)\n",
    "print(\"\\nXGBoost Classifier Accuracy:\", xgb_ac)\n",
    "\n",
    "f1 = f1_score(Y_test, y_pred, average=\"weighted\")\n",
    "print(\"\\nF1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d283ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train LightGBM Classifier\n",
    "lgb_model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=7)\n",
    "lgb_model.fit(X_train_resampled, Y_train_resampled)\n",
    "\n",
    "y_pred = lgb_model.predict(X_test)\n",
    "y_prob = lgb_model.predict_proba(X_test)\n",
    "\n",
    "lgb_ac = accuracy_score(Y_test, y_pred)\n",
    "print(\"\\nLightGBM Classifier Accuracy:\", lgb_ac)\n",
    "\n",
    "f1 = f1_score(Y_test, y_pred, average=\"weighted\")\n",
    "print(\"\\nF1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36be7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train CatBoost Classifier\n",
    "Cat_Boost = CatBoostClassifier(verbose=300, n_estimators=4000, learning_rate=0.3, depth=10, early_stopping_rounds=300)\n",
    "Cat_Boost.fit(X_train_resampled, Y_train_resampled)\n",
    "\n",
    "cb_ac = Cat_Boost.score(X_train_resampled, Y_train_resampled)\n",
    "print(\"\\nCatBoost Accuracy:\", cb_ac)\n",
    "\n",
    "y_pred = Cat_Boost.predict(X_test)\n",
    "y_prob = Cat_Boost.predict_proba(X_test)\n",
    "\n",
    "f1 = f1_score(Y_test, y_pred, average=\"weighted\")\n",
    "print(\"\\nF1 Score:\", f1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, y_pred)) \n",
    "\n",
    "cb_log_loss = log_loss(Y_test, y_prob)\n",
    "print(\"\\nLog Loss:\", cb_log_loss)\n",
    "\n",
    "if len(np.unique(Y_test)) == 2:\n",
    "    cb_roc_auc = roc_auc_score(Y_test, y_prob[:, 1])\n",
    "    print(\"\\nROC-AUC Score:\", cb_roc_auc)\n",
    "\n",
    "# Save model\n",
    "with open(\"finetuning_three.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Cat_Boost, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
