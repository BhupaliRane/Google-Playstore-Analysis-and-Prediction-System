{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d353d4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import RepeatedKFold, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef1cd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shree\\AppData\\Local\\Temp\\ipykernel_2836\\268454948.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category  Rating_Count  Installs  Free  Size_in_Mb  Content_Rating  \\\n",
      "0   2.24681         262.0   10000.0     1    4.200000         2.18234   \n",
      "1   2.70581           8.0      10.0     1   36.000000         2.18234   \n",
      "2   2.45978        2352.0  500000.0     1   26.000000         2.18234   \n",
      "3   1.93159          70.0   10000.0     1    0.097656         2.18234   \n",
      "4   1.93159           0.0      10.0     1    2.900000         2.18234   \n",
      "\n",
      "   Ad_Supported  In_App_Purchases  Editors_Choice  Transformed_Rating  \n",
      "0             0                 1               0                   5  \n",
      "1             1                 0               0                   5  \n",
      "2             0                 0               0                   3  \n",
      "3             0                 0               0                   3  \n",
      "4             0                 0               0                   0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Connect to SQL Server\n",
    "conn = mysql.connector.connect(host=\"localhost\", user=\"root\", password=\"root\", database=\"GooglePlayStore\")\n",
    "\n",
    "# Fetch Data\n",
    "query = \"SELECT * FROM rating\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Close connection\n",
    "conn.close()\n",
    "\n",
    "df = df.drop('id', axis=1)\n",
    "# Show first few rows\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52668d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformed_Rating\n",
       "0    92553\n",
       "4    50957\n",
       "5    36943\n",
       "3    15689\n",
       "2     3489\n",
       "1      369\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Transformed_Rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d3e34d",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2676efdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c055fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features Based on Decision Tree Importance:\n",
      "Index(['Rating_Count', 'Size_in_Mb'], dtype='object')\n",
      "\n",
      "RFE Feature Rankings:\n",
      "Category: 1\n",
      "Content_Rating: 1\n",
      "Rating_Count: 1\n",
      "Size_in_Mb: 1\n",
      "Installs: 2\n",
      "In_App_Purchases: 3\n",
      "Ad_Supported: 4\n",
      "Free: 5\n",
      "Editors_Choice: 6\n"
     ]
    }
   ],
   "source": [
    "# Feature and Target\n",
    "X = df.drop('Transformed_Rating', axis=1)\n",
    "Y = df['Transformed_Rating'].astype(int)  # Ensure categorical target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=7, stratify=Y)\n",
    "\n",
    "# Train Decision Tree and Calculate Feature Importance\n",
    "dt = DecisionTreeClassifier(random_state=7)\n",
    "dt.fit(X_train, Y_train)\n",
    "\n",
    "# Mean importance threshold\n",
    "mean_imp = dt.feature_importances_.mean()\n",
    "selected_features = X_train.columns[dt.feature_importances_ > mean_imp]\n",
    "print(\"Selected Features Based on Decision Tree Importance:\")\n",
    "print(selected_features)\n",
    "\n",
    "# Recursive Feature Elimination (RFE)\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(random_state=7))\n",
    "rfe.fit(X_train, Y_train)\n",
    "\n",
    "# Print feature rankings\n",
    "print(\"\\nRFE Feature Rankings:\")\n",
    "for rank, feature in sorted(zip(rfe.ranking_, X_train.columns)):\n",
    "    print(f\"{feature}: {rank}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e959360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "Transformed_Rating\n",
      "0    92553\n",
      "4    50957\n",
      "5    36943\n",
      "3    15689\n",
      "2     3489\n",
      "1      369\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target_col = \"Transformed_Rating\"\n",
    "class_counts = df[\"Transformed_Rating\"].value_counts()\n",
    "\n",
    "# Print class distribution\n",
    "print(\"Class Distribution:\")\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ff2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Model Logistic Regression\n",
    "\n",
    "logreg_c=LogisticRegression(max_iter=500, random_state=7, class_weight='balanced')\n",
    "logreg_c.fit(X_train,Y_train)\n",
    "logreg_pred=logreg_c.predict(X_test)\n",
    "logreg_cm=confusion_matrix(Y_test,logreg_pred)\n",
    "logreg_ac=accuracy_score(Y_test, logreg_pred)\n",
    "print('LogisticRegression_accuracy:',logreg_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c375a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Model RandomForest\n",
    "\n",
    "rdf_c=RandomForestClassifier(random_state=7)\n",
    "rdf_c.fit(X_train,Y_train)\n",
    "rdf_pred=rdf_c.predict(X_test)\n",
    "rdf_cm=confusion_matrix(Y_test,rdf_pred)\n",
    "rdf_ac=accuracy_score(rdf_pred,Y_test)\n",
    "print('RandomForest_Accuracy: ', rdf_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0e241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Model DecisionTree Classifier\n",
    "\n",
    "dtree_c=DecisionTreeClassifier(random_state=7,criterion='entropy', max_depth = 10, min_samples_leaf = 2, min_samples_split = 5)\n",
    "dtree_c.fit(X_train,Y_train)\n",
    "dtree_pred=dtree_c.predict(X_test)\n",
    "dtree_cm=confusion_matrix(Y_test,dtree_pred)\n",
    "dtree_ac=accuracy_score(dtree_pred,Y_test)\n",
    "print('DecisionTreeClassifier_Accuracy: ',dtree_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08458edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 0.5, 1.0],  \n",
    "    'binarize': [0.0, 0.5, 1.0],  \n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "NB = BernoulliNB()\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(NB, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b792da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Model Naive Bayesian\n",
    "\n",
    "NB = BernoulliNB(binarize = 0.0)\n",
    "NB.fit(X_train,Y_train)\n",
    "y_pred = NB.predict(X_test)\n",
    "nb_ac=accuracy_score(Y_test, y_pred)\n",
    "print(\"Bernoulli Naive Bayes_Accuracy: \", nb_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40a6e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgbc = HistGradientBoostingClassifier(max_iter=100, learning_rate=0.1, random_state=7)\n",
    "hgbc.fit(X_train, Y_train)\n",
    "y_pred = hgbc.predict(X_test)\n",
    "hgbc_ac = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "print(\"HistGradientBoosting Classifier Accuracy:\", hgbc_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd7d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying AdaBoost Classifier\n",
    "\n",
    "abc = AdaBoostClassifier(n_estimators=100, learning_rate=0.1, random_state=7)\n",
    "abc.fit(X_train, Y_train)\n",
    "y_pred = abc.predict(X_test)\n",
    "abc_ac = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "print(\"AdaBoost Classifier Accuracy:\", abc_ac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce54cc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=7)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(xgb, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21175e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying XGBoost Classifier\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=100, learning_rate=0.05, random_state=7, use_label_encoder=False, eval_metric='logloss', max_depth=9, gamma=0.5)\n",
    "xgb.fit(X_train, Y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "xgb_ac = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "print(\"XGBoost Classifier Accuracy:\", xgb_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470bbca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [-1, 5, 10],  # -1 means no limit\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "lgb_model = lgb.LGBMClassifier(random_state=7)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(lgb_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63a781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LightGBM classifier\n",
    "lgb_model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=7)\n",
    "\n",
    "# Train the model\n",
    "lgb_model.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = lgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "lgb_ac = accuracy_score(Y_test, y_pred)\n",
    "print(\"LightGBM Classifier Accuracy:\", lgb_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd32e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning CatBoost Classifier\n",
    "param_grid_catboost = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'depth': [4, 6, 8]\n",
    "}\n",
    "\n",
    "catboost = CatBoostClassifier(verbose=0)\n",
    "grid_search_catboost = GridSearchCV(catboost, param_grid_catboost, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_catboost.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score for CatBoost\n",
    "print(\"Best Parameters (CatBoost):\", grid_search_catboost.best_params_)\n",
    "print(\"Best Accuracy (CatBoost):\", grid_search_catboost.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf81031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Model CatBoost Model\n",
    "\n",
    "Cat_Boost = CatBoostClassifier(verbose = 0, n_estimators = 100)\n",
    "Cat_Boost.fit(X_train, Y_train)\n",
    "cb_ac=Cat_Boost.score(X_train, Y_train)\n",
    "print(\"CatBoost_Accuracy: \",cb_ac)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
